Current model
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 32, 640, 960]             896
              ReLU-2         [-1, 32, 640, 960]               0
            Conv2d-3         [-1, 32, 640, 960]           9,248
              ReLU-4         [-1, 32, 640, 960]               0
        conv_block-5         [-1, 32, 640, 960]               0
         MaxPool2d-6         [-1, 32, 320, 480]               0
            Conv2d-7         [-1, 64, 320, 480]          18,496
              ReLU-8         [-1, 64, 320, 480]               0
            Conv2d-9         [-1, 64, 320, 480]          36,928
             ReLU-10         [-1, 64, 320, 480]               0
       conv_block-11         [-1, 64, 320, 480]               0
        MaxPool2d-12         [-1, 64, 160, 240]               0
           Conv2d-13        [-1, 128, 160, 240]          73,856
             ReLU-14        [-1, 128, 160, 240]               0
           Conv2d-15        [-1, 128, 160, 240]         147,584
             ReLU-16        [-1, 128, 160, 240]               0
       conv_block-17        [-1, 128, 160, 240]               0
        MaxPool2d-18         [-1, 128, 80, 120]               0
           Conv2d-19         [-1, 256, 80, 120]         295,168
             ReLU-20         [-1, 256, 80, 120]               0
           Conv2d-21         [-1, 256, 80, 120]         590,080
             ReLU-22         [-1, 256, 80, 120]               0
       conv_block-23         [-1, 256, 80, 120]               0
        MaxPool2d-24          [-1, 256, 40, 60]               0
          Encoder-25  [[-1, 256, 40, 60], [-1, 256, 80, 120], [-1, 128, 160, 240], [-1, 64, 320, 480], [-1, 32, 640, 960]]               0
           Conv2d-26          [-1, 512, 40, 60]       1,180,160
             ReLU-27          [-1, 512, 40, 60]               0
           Conv2d-28          [-1, 512, 40, 60]       2,359,808
             ReLU-29          [-1, 512, 40, 60]               0
       conv_block-30          [-1, 512, 40, 60]               0
  ConvTranspose2d-31         [-1, 256, 80, 120]         524,544
           Conv2d-32         [-1, 256, 80, 120]       1,179,904
             ReLU-33         [-1, 256, 80, 120]               0
           Conv2d-34         [-1, 256, 80, 120]         590,080
             ReLU-35         [-1, 256, 80, 120]               0
       conv_block-36         [-1, 256, 80, 120]               0
  ConvTranspose2d-37        [-1, 128, 160, 240]         131,200
           Conv2d-38        [-1, 128, 160, 240]         295,040
             ReLU-39        [-1, 128, 160, 240]               0
           Conv2d-40        [-1, 128, 160, 240]         147,584
             ReLU-41        [-1, 128, 160, 240]               0
       conv_block-42        [-1, 128, 160, 240]               0
  ConvTranspose2d-43         [-1, 64, 320, 480]          32,832
           Conv2d-44         [-1, 64, 320, 480]          73,792
             ReLU-45         [-1, 64, 320, 480]               0
           Conv2d-46         [-1, 64, 320, 480]          36,928
             ReLU-47         [-1, 64, 320, 480]               0
       conv_block-48         [-1, 64, 320, 480]               0
  ConvTranspose2d-49         [-1, 32, 640, 960]           8,224
           Conv2d-50         [-1, 32, 640, 960]          18,464
             ReLU-51         [-1, 32, 640, 960]               0
           Conv2d-52         [-1, 32, 640, 960]           9,248
             ReLU-53         [-1, 32, 640, 960]               0
       conv_block-54         [-1, 32, 640, 960]               0
          Decoder-55         [-1, 32, 640, 960]               0
           Conv2d-56          [-1, 1, 640, 960]              33
          Sigmoid-57          [-1, 1, 640, 960]               0
================================================================
Total params: 7,760,097
Trainable params: 7,760,097
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 7.03
Forward/backward pass size (MB): 3370.31
Params size (MB): 29.60
Estimated Total Size (MB): 3406.95
----------------------------------------------------------------
This model takes up 7.8GB of VRAM when training with a batch size of 4.




Previous model (not yet trainable due to output and target inconsistencies)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 32, 638, 958]             896
              ReLU-2         [-1, 32, 638, 958]               0
            Conv2d-3         [-1, 32, 636, 956]           9,248
              ReLU-4         [-1, 32, 636, 956]               0
        conv_block-5         [-1, 32, 636, 956]               0
         MaxPool2d-6         [-1, 32, 318, 478]               0
            Conv2d-7         [-1, 64, 316, 476]          18,496
              ReLU-8         [-1, 64, 316, 476]               0
            Conv2d-9         [-1, 64, 314, 474]          36,928
             ReLU-10         [-1, 64, 314, 474]               0
       conv_block-11         [-1, 64, 314, 474]               0
        MaxPool2d-12         [-1, 64, 157, 237]               0
           Conv2d-13        [-1, 128, 155, 235]          73,856
             ReLU-14        [-1, 128, 155, 235]               0
           Conv2d-15        [-1, 128, 153, 233]         147,584
             ReLU-16        [-1, 128, 153, 233]               0
       conv_block-17        [-1, 128, 153, 233]               0
        MaxPool2d-18         [-1, 128, 76, 116]               0
           Conv2d-19         [-1, 256, 74, 114]         295,168
             ReLU-20         [-1, 256, 74, 114]               0
           Conv2d-21         [-1, 256, 72, 112]         590,080
             ReLU-22         [-1, 256, 72, 112]               0
       conv_block-23         [-1, 256, 72, 112]               0
        MaxPool2d-24          [-1, 256, 36, 56]               0
          Encoder-25  [[-1, 256, 36, 56], [-1, 256, 72, 112], [-1, 128, 153, 233], [-1, 64, 314, 474], [-1, 32, 636, 956]]               0
           Conv2d-26          [-1, 512, 34, 54]       1,180,160
             ReLU-27          [-1, 512, 34, 54]               0
           Conv2d-28          [-1, 512, 32, 52]       2,359,808
             ReLU-29          [-1, 512, 32, 52]               0
       conv_block-30          [-1, 512, 32, 52]               0
  ConvTranspose2d-31         [-1, 256, 64, 104]         524,544
           Conv2d-32         [-1, 256, 62, 102]       1,179,904
             ReLU-33         [-1, 256, 62, 102]               0
           Conv2d-34         [-1, 256, 60, 100]         590,080
             ReLU-35         [-1, 256, 60, 100]               0
       conv_block-36         [-1, 256, 60, 100]               0
  ConvTranspose2d-37        [-1, 128, 120, 200]         131,200
           Conv2d-38        [-1, 128, 118, 198]         295,040
             ReLU-39        [-1, 128, 118, 198]               0
           Conv2d-40        [-1, 128, 116, 196]         147,584
             ReLU-41        [-1, 128, 116, 196]               0
       conv_block-42        [-1, 128, 116, 196]               0
  ConvTranspose2d-43         [-1, 64, 232, 392]          32,832
           Conv2d-44         [-1, 64, 230, 390]          73,792
             ReLU-45         [-1, 64, 230, 390]               0
           Conv2d-46         [-1, 64, 228, 388]          36,928
             ReLU-47         [-1, 64, 228, 388]               0
       conv_block-48         [-1, 64, 228, 388]               0
  ConvTranspose2d-49         [-1, 32, 456, 776]           8,224
           Conv2d-50         [-1, 32, 454, 774]          18,464
             ReLU-51         [-1, 32, 454, 774]               0
           Conv2d-52         [-1, 32, 452, 772]           9,248
             ReLU-53         [-1, 32, 452, 772]               0
       conv_block-54         [-1, 32, 452, 772]               0
          Decoder-55         [-1, 32, 452, 772]               0
           Conv2d-56          [-1, 1, 452, 772]              33
          Sigmoid-57          [-1, 1, 452, 772]               0
================================================================
Total params: 7,760,097
Trainable params: 7,760,097
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 7.03
Forward/backward pass size (MB): 2540.32
Params size (MB): 29.60
Estimated Total Size (MB): 2576.95
----------------------------------------------------------------





Original model from https://github.com/milesial/Pytorch-UNet
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 640, 960]           1,728
       BatchNorm2d-2         [-1, 64, 640, 960]             128
              ReLU-3         [-1, 64, 640, 960]               0
            Conv2d-4         [-1, 64, 640, 960]          36,864
       BatchNorm2d-5         [-1, 64, 640, 960]             128
              ReLU-6         [-1, 64, 640, 960]               0
        DoubleConv-7         [-1, 64, 640, 960]               0
         MaxPool2d-8         [-1, 64, 320, 480]               0
            Conv2d-9        [-1, 128, 320, 480]          73,728
      BatchNorm2d-10        [-1, 128, 320, 480]             256
             ReLU-11        [-1, 128, 320, 480]               0
           Conv2d-12        [-1, 128, 320, 480]         147,456
      BatchNorm2d-13        [-1, 128, 320, 480]             256
             ReLU-14        [-1, 128, 320, 480]               0
       DoubleConv-15        [-1, 128, 320, 480]               0
             Down-16        [-1, 128, 320, 480]               0
        MaxPool2d-17        [-1, 128, 160, 240]               0
           Conv2d-18        [-1, 256, 160, 240]         294,912
      BatchNorm2d-19        [-1, 256, 160, 240]             512
             ReLU-20        [-1, 256, 160, 240]               0
           Conv2d-21        [-1, 256, 160, 240]         589,824
      BatchNorm2d-22        [-1, 256, 160, 240]             512
             ReLU-23        [-1, 256, 160, 240]               0
       DoubleConv-24        [-1, 256, 160, 240]               0
             Down-25        [-1, 256, 160, 240]               0
        MaxPool2d-26         [-1, 256, 80, 120]               0
           Conv2d-27         [-1, 512, 80, 120]       1,179,648
      BatchNorm2d-28         [-1, 512, 80, 120]           1,024
             ReLU-29         [-1, 512, 80, 120]               0
           Conv2d-30         [-1, 512, 80, 120]       2,359,296
      BatchNorm2d-31         [-1, 512, 80, 120]           1,024
             ReLU-32         [-1, 512, 80, 120]               0
       DoubleConv-33         [-1, 512, 80, 120]               0
             Down-34         [-1, 512, 80, 120]               0
        MaxPool2d-35          [-1, 512, 40, 60]               0
           Conv2d-36         [-1, 1024, 40, 60]       4,718,592
      BatchNorm2d-37         [-1, 1024, 40, 60]           2,048
             ReLU-38         [-1, 1024, 40, 60]               0
           Conv2d-39         [-1, 1024, 40, 60]       9,437,184
      BatchNorm2d-40         [-1, 1024, 40, 60]           2,048
             ReLU-41         [-1, 1024, 40, 60]               0
       DoubleConv-42         [-1, 1024, 40, 60]               0
             Down-43         [-1, 1024, 40, 60]               0
  ConvTranspose2d-44         [-1, 512, 80, 120]       2,097,664
           Conv2d-45         [-1, 512, 80, 120]       4,718,592
      BatchNorm2d-46         [-1, 512, 80, 120]           1,024
             ReLU-47         [-1, 512, 80, 120]               0
           Conv2d-48         [-1, 512, 80, 120]       2,359,296
      BatchNorm2d-49         [-1, 512, 80, 120]           1,024
             ReLU-50         [-1, 512, 80, 120]               0
       DoubleConv-51         [-1, 512, 80, 120]               0
               Up-52         [-1, 512, 80, 120]               0
  ConvTranspose2d-53        [-1, 256, 160, 240]         524,544
           Conv2d-54        [-1, 256, 160, 240]       1,179,648
      BatchNorm2d-55        [-1, 256, 160, 240]             512
             ReLU-56        [-1, 256, 160, 240]               0
           Conv2d-57        [-1, 256, 160, 240]         589,824
      BatchNorm2d-58        [-1, 256, 160, 240]             512
             ReLU-59        [-1, 256, 160, 240]               0
       DoubleConv-60        [-1, 256, 160, 240]               0
               Up-61        [-1, 256, 160, 240]               0
  ConvTranspose2d-62        [-1, 128, 320, 480]         131,200
           Conv2d-63        [-1, 128, 320, 480]         294,912
      BatchNorm2d-64        [-1, 128, 320, 480]             256
             ReLU-65        [-1, 128, 320, 480]               0
           Conv2d-66        [-1, 128, 320, 480]         147,456
      BatchNorm2d-67        [-1, 128, 320, 480]             256
             ReLU-68        [-1, 128, 320, 480]               0
       DoubleConv-69        [-1, 128, 320, 480]               0
               Up-70        [-1, 128, 320, 480]               0
  ConvTranspose2d-71         [-1, 64, 640, 960]          32,832
           Conv2d-72         [-1, 64, 640, 960]          73,728
      BatchNorm2d-73         [-1, 64, 640, 960]             128
             ReLU-74         [-1, 64, 640, 960]               0
           Conv2d-75         [-1, 64, 640, 960]          36,864
      BatchNorm2d-76         [-1, 64, 640, 960]             128
             ReLU-77         [-1, 64, 640, 960]               0
       DoubleConv-78         [-1, 64, 640, 960]               0
               Up-79         [-1, 64, 640, 960]               0
           Conv2d-80          [-1, 2, 640, 960]             130
          OutConv-81          [-1, 2, 640, 960]               0
================================================================
Total params: 31,037,698
Trainable params: 31,037,698
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 7.03
Forward/backward pass size (MB): 9571.88
Params size (MB): 118.40
Estimated Total Size (MB): 9697.31
----------------------------------------------------------------